{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpletctj6\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Authenticate with W&B\n",
    "wandb.login(timeout=1024)\n",
    "\n",
    "# Initialize a list to store coverage and shannon entropy data\n",
    "experiments_data = {}\n",
    "nb_max_samples = int(1e6)\n",
    "\n",
    "TOTAL_TIME_STEPS = 1_000_000\n",
    "TOTAL_POINTS = 1_000\n",
    "NUM_ENVS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure project and other parameters if necessary\n",
    "project_name = \"run_away_sac_exploit_2\"\n",
    "entity = \"pletctj6\"\n",
    "# Retrieve the runs from the project\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{entity}/{project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show nb finished "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "* config : config for the run\n",
    "* history : Time evolution of all the data recorded during the run as columns in a pandas dataframe\n",
    "* summary : last sample of the data recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237a713fbf344038ede5eff00e48df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing runs:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from envs.config_env import config as config_env\n",
    "\n",
    "def process_run(run, \n",
    "                metrics = {\n",
    "                            \"config\": [\"exp_name\", \"env_id\", \"seed\", \"keep_extrinsic_reward\", \"beta_ratio\", \"name\"],\n",
    "                            \"history\": [\"charts/episodic_return\",  \"_step\"],\n",
    "                            \"summary\": [\"charts/episodic_return\",  \"_step\"]\n",
    "                },\n",
    "                config_env=config_env):\n",
    "    # Vérification de l'état du run\n",
    "    # if run.state != \"finished\":\n",
    "    #     # print(f\"Skipping run {run.name} because it is not finished.\")\n",
    "    #     return None\n",
    "    ##### check job status #####\n",
    "    if run.state != \"finished\":\n",
    "        return None\n",
    "    ##### CONFIGURATION #####\n",
    "    config = run.config\n",
    "    config_metrics = {key: None for key in metrics['config']}\n",
    "    for key in config_metrics.keys():\n",
    "        try:\n",
    "            config_metrics[key] = config.get(key)\n",
    "        except:\n",
    "            print(f\"Skipping run {run.name} because it doesn't have the data {key} in config.\")\n",
    "            return None\n",
    "        \n",
    "    ##### HISTORY #####\n",
    "    history_metrics_full = run.history(samples=nb_max_samples, keys=metrics['history'], x_axis=\"_step\", pandas=(True), stream=\"default\")\n",
    "    history_metrics = {key: None for key in metrics['history']}\n",
    "    for key in history_metrics.keys():\n",
    "        try : \n",
    "            history_metrics[key] = history_metrics_full[key]\n",
    "        except:\n",
    "            print(f\"Skipping run {run.name} because it doesn't have the data {key} in history.\")\n",
    "            return None\n",
    "\n",
    "    ##### SUMMARY #####\n",
    "    summary_metrics = {key: None for key in metrics['summary']}\n",
    "    for key in summary_metrics.keys():\n",
    "        if key in run.summary:\n",
    "            summary_metrics[key] = run.summary._json_dict[key]\n",
    "        else:\n",
    "            summary_metrics[key] = history_metrics[key].iloc[-1]\n",
    "        \n",
    "    # Check env id \n",
    "    type_id = config_env[run.config.get('env_id')]['type_id']\n",
    "    return {\n",
    "        'exp_name': config_metrics['exp_name'],\n",
    "        'env_name': config_metrics['env_id'],\n",
    "        'type_id': type_id,\n",
    "        'seed': config_metrics['seed'],\n",
    "        'data': {\n",
    "            'summary_metrics': summary_metrics,\n",
    "            'history_metrics': history_metrics,\n",
    "            'config_metrics': config_metrics,\n",
    "            'config': config\n",
    "        }\n",
    "    }\n",
    "\n",
    "# experiments_data = {}\n",
    "max_workers = 4\n",
    "# Utilisation de ThreadPoolExecutor pour paralléliser les exécutions de runs\n",
    "# Spécifiez le nombre de threads avec max_workers, par exemple 4 threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = {executor.submit(process_run, run) for run in runs}\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing runs\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            exp_name = result['exp_name']\n",
    "            env_name = result['env_name']\n",
    "            type_id = result['type_id']\n",
    "            seed = result['seed']\n",
    "            data = result['data']\n",
    "            if exp_name not in experiments_data:\n",
    "                experiments_data[exp_name] = {}\n",
    "            if type_id not in experiments_data[exp_name]:\n",
    "                experiments_data[exp_name][type_id] = {}\n",
    "            if env_name not in experiments_data[exp_name][type_id]:\n",
    "                experiments_data[exp_name][type_id][env_name] = {}\n",
    "            # if seed exist already, we keep the one with the highest return\n",
    "            if seed in experiments_data[exp_name][type_id][env_name].keys():\n",
    "                if experiments_data[exp_name][type_id][env_name][seed]['history_metrics']['charts/episodic_return'].max() < data['history_metrics']['charts/episodic_return'].max():\n",
    "                    experiments_data[exp_name][type_id][env_name][seed] = data\n",
    "            else:\n",
    "                experiments_data[exp_name][type_id][env_name][seed] = data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "dict_keys(['Humanoid-v3', 'Ant-v3', 'Hopper-v3', 'HalfCheetah-v3', 'Walker2d-v3'])\n"
     ]
    }
   ],
   "source": [
    "# experiments_data['sac_icm']['mujoco']['HalfCheetah-v3'][3]['history_metrics']['specific/episodic_return']\n",
    "print(type(experiments_data['sac_vanilla']['mujoco']['HalfCheetah-v3'][3]['history_metrics']['charts/episodic_return']))\n",
    "print(experiments_data['sac_vanilla']['mujoco'].keys())\n",
    "\n",
    "# # check nan in data\n",
    "# is_nan = experiments_data['apt_ppo']['mujoco']['HalfCheetah-v3'][3]['history_metrics']['specific/episodic_return'].isnull().values.any()\n",
    "# print(is_nan)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traductor_exp(exp_name:str):\n",
    "    # remove sac from name if it is present\n",
    "    exp_name = exp_name.replace('_sac', '')\n",
    "    # capitalize the full name\n",
    "    exp_name = exp_name.upper()\n",
    "    return exp_name \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### list + params colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v1wsac', 'v1klsac', 'ngu_sac', 'sac_vanilla', 'apt_sac', 'rnd_sac', 'icm_sac', 'aux_sac']\n",
      "['mujoco', 'maze']\n",
      "['Humanoid-v3', 'Walker2d-v3', 'Ant-v3', 'Hopper-v3', 'HalfCheetah-v3', 'Maze-Hard-v0', 'Maze-Ur-v0', 'Maze-Easy-v0']\n"
     ]
    }
   ],
   "source": [
    "# algo\n",
    "list_algos = list(experiments_data.keys())\n",
    "# type\n",
    "list_type = list(experiments_data['sac_vanilla'].keys())\n",
    "# env\n",
    "list_env = []\n",
    "for i in range(len(list_type)):\n",
    "    list_env += list(list(experiments_data[list_algos[1]][list_type[i]].keys()))\n",
    "\n",
    "print(list_algos)\n",
    "print(list_type)\n",
    "print(list_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in list_algos:\n",
    "    for type_env in list_type:\n",
    "        for env in list_env:\n",
    "            if env in experiments_data[algo][type_env]:\n",
    "                for seed in experiments_data[algo][type_env][env]:\n",
    "                    # print(f\"Algo: {algo}, Type: {type_env}, Env: {env}, Seed: {seed}\")\n",
    "                    experiments_data[algo][type_env][env][seed]['history_metrics']['charts/cumulative_reward'] = experiments_data[algo][type_env][env][seed]['history_metrics']['charts/episodic_return'].cummax()\n",
    "                    experiments_data[algo][type_env][env][seed]['summary_metrics']['charts/cumulative_reward'] = experiments_data[algo][type_env][env][seed]['history_metrics']['charts/episodic_return'].max()\n",
    "\n",
    "            else:\n",
    "                # print(f\"Algo: {algo}, Type: {type_env}, Env: {env}, Seed: None\")\n",
    "                # print(\"\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charts/cumulative_reward mujoco Normalized DataFrame:\n",
      "| exp_name    | Ant-v3             | HalfCheetah-v3      | Hopper-v3          | Humanoid-v3        | Walker2d-v3        |\n",
      "|:------------|:-------------------|:--------------------|:-------------------|:-------------------|:-------------------|\n",
      "| APT         | 1042.92 +/- 69.57  | 10316.75 +/- 138.11 | 3017.37 +/- 450.99 | 3330.95 +/- 739.97 | 2258.74 +/- 290.4  |\n",
      "| AUX         | 5452.47 +/- 257.29 | 11127.26 +/- 243.28 | 2197.51 +/- 474.66 | 3477.43 +/- 706.62 | 4767.75 +/- 91.44  |\n",
      "| ICM         | 4512.31 +/- 447.36 | 11161.58 +/- 163.53 | 3651.47 +/- 171.06 | 3880.75 +/- 491.1  | 5507.85 +/- 196.94 |\n",
      "| NGU         | 975.04 +/- 12.47   | 2976.61 +/- 584.02  | 1360.27 +/- 54.27  | 415.38 +/- 93.6    | 1636.31 +/- 88.22  |\n",
      "| RND         | 4427.05 +/- 158.72 | 10901.39 +/- 108.64 | 3044.78 +/- 383.86 | 5103.58 +/- 34.03  | 5756.03 +/- 42.18  |\n",
      "| SAC_VANILLA | 4972.15 +/- 95.01  | 12197.12 +/- 79.05  | 3861.94 +/- 28.65  | 5163.54 +/- 70.49  | 5650.29 +/- 108.45 |\n",
      "| V1KLSAC     | 4744.36 +/- 372.64 | 13826.25 +/- 361.06 | 3646.79 +/- 196.09 | 5399.42 +/- 43.31  | 6000.9 +/- 498.47  |\n",
      "| V1WSAC      | 7121.94 +/- 49.22  | 12997.86 +/- 987.02 | 982.05 +/- 57.99   | 5342.87 +/- 74.44  | 6148.62 +/- 86.46  |\n",
      "charts/cumulative_reward maze Normalized DataFrame:\n",
      "| exp_name    | Maze-Easy-v0   | Maze-Hard-v0   | Maze-Ur-v0    |\n",
      "|:------------|:---------------|:---------------|:--------------|\n",
      "| APT         | 1.27 +/- 0.0   | 0.56 +/- 0.05  | 1.0 +/- 0.0   |\n",
      "| AUX         | 1.27 +/- 0.0   | 0.51 +/- 0.0   | 0.5 +/- 0.0   |\n",
      "| ICM         | 1.27 +/- 0.0   | 0.61 +/- 0.1   | 0.8 +/- 0.12  |\n",
      "| NGU         | 1.17 +/- 0.03  | 0.5 +/- 0.0    | 0.55 +/- 0.07 |\n",
      "| RND         | 1.27 +/- 0.0   | 0.51 +/- 0.0   | 0.9 +/- 0.1   |\n",
      "| SAC_VANILLA | 1.03 +/- 0.01  | 0.51 +/- 0.0   | 0.5 +/- 0.0   |\n",
      "| V1KLSAC     | 1.25 +/- 0.02  | 0.51 +/- 0.0   | 0.64 +/- 0.1  |\n",
      "| V1WSAC      | 1.27 +/- 0.0   | 0.69 +/- 0.15  | 0.9 +/- 0.1   |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "def extract_final_values(experiments_data, \n",
    "                        keys=['charts/cumulative_reward'],\n",
    "                        type_id_default = None, \n",
    "                        env_name_default = None):\n",
    "    key_data = {}\n",
    "    for exp_name in experiments_data.keys():\n",
    "        for type_id in experiments_data[exp_name].keys():\n",
    "            if type_id_default is not None and type_id not in type_id_default:\n",
    "                continue\n",
    "            for env_name in experiments_data[exp_name][type_id].keys():\n",
    "                if env_name_default is not None and env_name not in env_name_default:\n",
    "                    continue\n",
    "                for seed in experiments_data[exp_name][type_id][env_name].keys():\n",
    "                    run_data = experiments_data[exp_name][type_id][env_name][seed]\n",
    "                    for key in keys:\n",
    "                        if key not in key_data:\n",
    "                            key_data[key] = []\n",
    "                        metric = run_data['summary_metrics'][key]\n",
    "                        key_data[key].append({\n",
    "                            'exp_name': traductor_exp(exp_name),\n",
    "                            'env_name': env_name,\n",
    "                            'seed': seed,\n",
    "                            key: metric\n",
    "                        })\n",
    "    key_df = {}\n",
    "    for key in keys:\n",
    "        key_df[key] = pd.DataFrame(key_data[key])\n",
    "    return key_df \n",
    "\n",
    "# Fonction pour normaliser le coverage par le coverage maximal de l'environnement\n",
    "def normalize(df, key):\n",
    "    normalized_df = df[key].copy()\n",
    "    normalized_df[key+'_max'] = normalized_df.groupby(['env_name'])[key].transform('max')\n",
    "    normalized_df[key+'_mean'] = normalized_df.groupby(['exp_name', 'env_name'])[key].transform('mean')\n",
    "    normalized_df[key+'_std'] = normalized_df.groupby(['exp_name', 'env_name'])[key].transform('std')\n",
    "    normalized_df[key+'_ste'] = normalized_df.groupby(['exp_name', 'env_name'])[key].transform('sem')\n",
    "    \n",
    "    # normalized_df[key+'_normalized_mean'] = (normalized_df[key+'_mean'] / np.abs(normalized_df[key+'_max'])) * 100\n",
    "    # normalized_df[key+'_normalized_std'] = (normalized_df[key+'_std'] / np.abs(normalized_df[key+'_max'])) * 100\n",
    "    # normalized_df[key+'_normalized_ste'] = (normalized_df[key+'_ste'] / np.abs(normalized_df[key+'_max'])) * 100\n",
    "\n",
    "    normalized_df[key+'_normalized_mean'] = normalized_df[key+'_mean']\n",
    "    normalized_df[key+'_normalized_std'] = normalized_df[key+'_std'] \n",
    "    normalized_df[key+'_normalized_ste'] = normalized_df[key+'_ste'] \n",
    "    # cast as int \n",
    "    normalized_df[key+'_normalized_mean'] = normalized_df[key+'_normalized_mean']\n",
    "    normalized_df[key+'_normalized_std'] = normalized_df[key+'_normalized_std']\n",
    "    normalized_df[key+'_normalized_ste'] = normalized_df[key+'_normalized_ste']\n",
    "    \n",
    "    normalized_df = normalized_df[['exp_name', 'env_name', key+'_normalized_mean', key+'_normalized_std', key+'_normalized_ste']].drop_duplicates()\n",
    "    return normalized_df\n",
    "\n",
    "\n",
    "def format_results(df, value_col_mean, value_col_std):\n",
    "    formatted_results = df.pivot(index='exp_name', columns='env_name', values=[value_col_mean, value_col_std])\n",
    "    formatted_results = formatted_results.swaplevel(axis=1).sort_index(axis=1, level=0)\n",
    "    for env in formatted_results.columns.levels[0]:\n",
    "        formatted_results[(env, 'mean +/- std')] = formatted_results[(env, value_col_mean)].round(2).astype(str) + \" +/- \" + formatted_results[(env, value_col_std)].round(2).astype(str)\n",
    "    formatted_results = formatted_results.loc[:, pd.IndexSlice[:, 'mean +/- std']]\n",
    "    formatted_results.columns = formatted_results.columns.droplevel(1)\n",
    "    return formatted_results\n",
    "\n",
    "\n",
    "def dataframe_to_markdown(df, filename):\n",
    "    def bold_max_in_column(df):\n",
    "        df_bold = df.copy()\n",
    "        for col in df.columns:\n",
    "            if col != 'exp_name':\n",
    "                max_value = df[col].apply(lambda x: float(x.split(' +/- ')[0])).max()\n",
    "                df_bold[col] = df[col].apply(lambda x: f\"**{x}**\" if float(x.split(' +/- ')[0]) == max_value else x)\n",
    "        return df_bold\n",
    "    \n",
    "    # Apply bold formatting to each column\n",
    "    df_bold = bold_max_in_column(df)\n",
    "    \n",
    "    # Convert DataFrame to Markdown format\n",
    "    markdown_table = tabulate(df_bold, headers='keys', tablefmt='pipe', showindex=True)\n",
    "    \n",
    "    # Replace '/' in filename\n",
    "    filename = filename.replace('/', '_')\n",
    "    \n",
    "    # Write the Markdown table to a file\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(markdown_table)\n",
    "\n",
    "def dataframe_to_latex(df, filename='latex_table.txt', save=False):\n",
    "    def bold_max_in_column(df):\n",
    "        df_bold = df.copy()\n",
    "        for col in df.columns:\n",
    "            if col != 'exp_name':\n",
    "                max_value = df[col].apply(lambda x: float(x.split(' +/- ')[0])).max()\n",
    "                df_bold[col] = df[col].apply(lambda x: f\"\\\\textbf{{{x}}}\" if float(x.split(' +/- ')[0]) == max_value else x)\n",
    "        return df_bold\n",
    "    \n",
    "    # Apply bold formatting to each column\n",
    "    df_bold = bold_max_in_column(df)\n",
    "    \n",
    "    # Convert DataFrame to LaTeX format\n",
    "    latex_table = tabulate(df_bold, headers='keys', tablefmt='latex', showindex=True)\n",
    "    \n",
    "    # Correct the LaTeX syntax\n",
    "    latex_table = latex_table.replace(r'\\textbackslash{}', '\\\\').replace(r'\\\\textbf', r'\\textbf').replace(r'\\{', '{').replace(r'\\}', '}')\n",
    "    \n",
    "    # Replace '/' in filename\n",
    "    filename = filename.replace('/', '_')\n",
    "    \n",
    "    if save:\n",
    "        # Delete file if it already exists\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(latex_table)\n",
    "    \n",
    "    return latex_table\n",
    "\n",
    "\n",
    "\n",
    "# Extraction des valeurs finales\n",
    "for type_id in list_type:\n",
    "    key_df = extract_final_values(experiments_data, type_id_default=[type_id], env_name_default=list(experiments_data[list_algos[1]][type_id].keys()))\n",
    "    for key in key_df.keys():\n",
    "        # coverage normalization \n",
    "        data_normalized_df = normalize(key_df, key)\n",
    "        # # Formater les résultats\n",
    "        data_formatted = format_results(data_normalized_df, key+'_normalized_mean', key+'_normalized_ste')\n",
    "        # # # Enregistrement des DataFrames au format Markdown\n",
    "        # # dataframe_to_markdown(coverage_formatted, 'coverage_normalized.md')\n",
    "        # dataframe_to_markdown(data_formatted, 'shannon_entropy.md')\n",
    "\n",
    "        # # Enregistrement des DataFrames au format LaTeX\n",
    "        dataframe_to_latex(data_formatted, f'{key}_{type_id}_normalized.tex', save=True )\n",
    "\n",
    "        # mise en forme en markdown\n",
    "        # dataframe_to_markdown(data_formatted, f'{key}_{type_id}_normalized.md')\n",
    "        # Affichage des résultats\n",
    "        print(key + \" \" + type_id +\" Normalized DataFrame:\")\n",
    "        print(tabulate(data_formatted, headers='keys', tablefmt='pipe', showindex=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key : charts/episodic_return\n",
      "exp_name : ngu_sac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : ngu_sac\n",
      "key : _step\n",
      "exp_name : ngu_sac\n",
      "key : charts/episodic_return\n",
      "exp_name : ngu_sac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : ngu_sac\n",
      "key : _step\n",
      "exp_name : ngu_sac\n",
      "key : charts/episodic_return\n",
      "exp_name : ngu_sac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : ngu_sac\n",
      "key : _step\n",
      "exp_name : ngu_sac\n",
      "key : charts/episodic_return\n",
      "exp_name : ngu_sac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : ngu_sac\n",
      "key : _step\n",
      "exp_name : ngu_sac\n",
      "key : charts/episodic_return\n",
      "exp_name : ngu_sac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : ngu_sac\n",
      "key : _step\n",
      "exp_name : ngu_sac\n",
      "key : charts/episodic_return\n",
      "exp_name : ngu_sac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : ngu_sac\n",
      "key : _step\n",
      "exp_name : ngu_sac\n",
      "key : charts/episodic_return\n",
      "exp_name : v1wsac\n",
      "key : charts/cumulative_reward\n",
      "exp_name : v1wsac\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'charts/cumulative_reward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 69\u001b[0m\n\u001b[1;32m     64\u001b[0m                 data[exp_name][type_id][env_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_step\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dict_max[env_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_step\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 69\u001b[0m data_clean \u001b[38;5;241m=\u001b[39m \u001b[43madd_nomalized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiments_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36madd_nomalized_data\u001b[0;34m(experiments_data, keys)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey :\u001b[39m\u001b[38;5;124m\"\u001b[39m, key)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_name :\u001b[39m\u001b[38;5;124m\"\u001b[39m, exp_name)\n\u001b[0;32m---> 28\u001b[0m     dict_max[env_name][key] \u001b[38;5;241m=\u001b[39m \u001b[43mexperiments_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtype_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary_metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[1;32m     30\u001b[0m     dict_max[env_name][key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(dict_max[env_name][key], experiments_data[exp_name][type_id][env_name][seed][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][key])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'charts/cumulative_reward'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fonction pour vérifier si une liste est vide\n",
    "def is_not_empty(obj):\n",
    "    if isinstance(obj, pd.Series):\n",
    "        return not obj.empty\n",
    "    return bool(obj)\n",
    "\n",
    "def interpolate_and_fill_single_metric(values, global_steps, max_global_step):\n",
    "    values = values.dropna()\n",
    "    # Créer une série avec des NaNs pour les global_steps manquants\n",
    "    all_steps = np.arange(max_global_step + 1)\n",
    "    series = values.reindex(all_steps).interpolate(method='linear').ffill().bfill()\n",
    "    return series\n",
    "\n",
    "def add_nomalized_data(experiments_data, keys=['charts/episodic_return', 'charts/cumulative_reward', '_step']):\n",
    "    # final data \n",
    "    data = {}\n",
    "    # max data evaluation \n",
    "    dict_max = {}\n",
    "    for exp_name in experiments_data.keys():\n",
    "        for type_id in experiments_data[exp_name].keys():\n",
    "            for env_name in experiments_data[exp_name][type_id].keys():\n",
    "                dict_max[env_name] = {} if env_name not in dict_max else dict_max[env_name]\n",
    "                for seed in experiments_data[exp_name][type_id][env_name].keys():\n",
    "                    for key in keys:\n",
    "                        if key not in dict_max[env_name]:\n",
    "                            print(\"key :\", key)\n",
    "                            print(\"exp_name :\", exp_name)\n",
    "                            dict_max[env_name][key] = experiments_data[exp_name][type_id][env_name][seed]['summary_metrics'][key]\n",
    "                        else : \n",
    "                            dict_max[env_name][key] = max(dict_max[env_name][key], experiments_data[exp_name][type_id][env_name][seed]['summary_metrics'][key])\n",
    "                        # nb_values\n",
    "                        if \"nb_values\" not in dict_max[env_name]: dict_max[env_name][\"nb_values\"] = experiments_data[exp_name][type_id][env_name][seed]['history_metrics'][key].shape[0]  \n",
    "                        else : dict_max[env_name][\"nb_values\"] = max(experiments_data[exp_name][type_id][env_name][seed]['history_metrics'][key].shape[0], dict_max[env_name][\"nb_values\"])\n",
    "    # add normalized data\n",
    "    for exp_name in experiments_data.keys():\n",
    "        data[exp_name] = {} if exp_name not in data else data[exp_name]\n",
    "        for type_id in experiments_data[exp_name].keys():\n",
    "            data[exp_name][type_id] = {} if type_id not in data[exp_name] else data[exp_name][type_id]\n",
    "            for env_name in experiments_data[exp_name][type_id].keys():\n",
    "                data[exp_name][type_id][env_name] = {} if env_name not in data[exp_name][type_id] else data[exp_name][type_id][env_name]\n",
    "                for key in keys:\n",
    "                    if key == '_step':\n",
    "                        continue\n",
    "                    data_seeds = []\n",
    "                    for seed in experiments_data[exp_name][type_id][env_name].keys():\n",
    "                        run_data = experiments_data[exp_name][type_id][env_name][seed]\n",
    "                        values = run_data['history_metrics'][key]\n",
    "                        # repeat last value nb_values-values times\n",
    "                        df_comp = pd.Series(np.repeat(values.iloc[-1], dict_max[env_name][\"nb_values\"]-values.shape[0]))\n",
    "                        values = pd.concat([values, df_comp]).values.reshape(-1, 1)\n",
    "                        data_seeds.append(pd.Series(values.flatten()))\n",
    "                \n",
    "                    df_concat = pd.concat(data_seeds, axis=1)\n",
    "                    # df_mean = (df_concat.mean(axis=1)/dict_max[env_name][key])*100.0\n",
    "                    # df_std = (df_concat.std(axis=1)/dict_max[env_name][key])*100.0\n",
    "                    # df_ste = (df_concat.sem(axis=1)/dict_max[env_name][key])*100.0\n",
    "                    df_mean = df_concat.mean(axis=1)\n",
    "                    df_std = df_concat.std(axis=1)\n",
    "                    df_ste = df_concat.sem(axis=1)\n",
    "                    data[exp_name][type_id][env_name]['normalized_mean_'+key] = df_mean\n",
    "                    data[exp_name][type_id][env_name]['normalized_std_'+key] = df_std\n",
    "                    data[exp_name][type_id][env_name]['normalized_ste_'+key] = df_ste\n",
    "                data[exp_name][type_id][env_name]['_step'] = run_data['history_metrics']['_step']\n",
    "                data[exp_name][type_id][env_name]['max_step'] = dict_max[env_name][\"_step\"]\n",
    "    return data\n",
    "                    \n",
    "                        \n",
    "        \n",
    "data_clean = add_nomalized_data(experiments_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mujoco', 'maze'])\n",
      "dict_keys(['Walker2d-v3', 'Ant-v3', 'Hopper-v3', 'HalfCheetah-v3', 'Humanoid-v3'])\n",
      "dict_keys(['Maze-Hard-v0', 'Maze-Ur-v0', 'Maze-Easy-v0'])\n",
      "dict_keys(['v1wsac', 'v1klsac', 'sac_vanilla', 'apt_sac', 'rnd_sac', 'icm_sac', 'aux_sac'])\n",
      "dict_keys(['normalized_mean_charts/episodic_return', 'normalized_std_charts/episodic_return', 'normalized_ste_charts/episodic_return', 'normalized_mean_charts/cumulative_reward', 'normalized_std_charts/cumulative_reward', 'normalized_ste_charts/cumulative_reward', '_step', 'max_step'])\n"
     ]
    }
   ],
   "source": [
    "print(data_clean[list(data_clean.keys())[0]].keys())\n",
    "print(data_clean[list(data_clean.keys())[0]]['mujoco'].keys())\n",
    "print(data_clean[list(data_clean.keys())[0]]['maze'].keys())\n",
    "print(data_clean.keys())\n",
    "print(data_clean['icm_sac']['mujoco']['HalfCheetah-v3'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Déterminer les couleurs pour chaque algorithme\u001b[39;00m\n\u001b[1;32m      2\u001b[0m palette \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtab20\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcolors\n\u001b[0;32m----> 3\u001b[0m color_map \u001b[38;5;241m=\u001b[39m {exp_name: palette[i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(palette)] \u001b[38;5;28;01mfor\u001b[39;00m i, exp_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdata_clean\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())}\n\u001b[1;32m      4\u001b[0m key_plot \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharts/cumulative_reward\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m type_id \u001b[38;5;129;01min\u001b[39;00m data_clean[\u001b[38;5;28mlist\u001b[39m(data_clean\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_clean' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Déterminer les couleurs pour chaque algorithme\n",
    "palette = plt.get_cmap(\"tab20\").colors\n",
    "color_map = {exp_name: palette[i % len(palette)] for i, exp_name in enumerate(data_clean.keys())}\n",
    "key_plot = ['charts/cumulative_reward']\n",
    "for type_id in data_clean[list(data_clean.keys())[0]].keys():\n",
    "    for env in data_clean[list(data_clean.keys())[0]][type_id].keys():\n",
    "        for data_key in key_plot : \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            # try : \n",
    "            for exp_name in data_clean.keys():\n",
    "                if env in data_clean[exp_name][type_id]:\n",
    "                    # if exp_name != algo:\n",
    "                    #     continue\n",
    "                    # if data_key not in data[type_id][env]:\n",
    "                    #     continue\n",
    "                    # x = data[type_id][env]['_step']\n",
    "                    if type_id=='mujoco' :\n",
    "                        x= np.linspace(0, TOTAL_TIME_STEPS*NUM_ENVS,data_clean[exp_name][type_id][env]['normalized_mean_'+data_key].shape[0])\n",
    "                    else:\n",
    "                        x = np.linspace(0, data_clean[exp_name][type_id][env]['max_step']*NUM_ENVS, data_clean[exp_name][type_id][env]['normalized_mean_'+data_key].shape[0])\n",
    "                    mean = data_clean[exp_name][type_id][env]['normalized_mean_'+data_key][:len(x)] \n",
    "                    std = data_clean[exp_name][type_id][env]['normalized_std_'+data_key][:len(x)]               \n",
    "                    ste = data_clean[exp_name][type_id][env]['normalized_ste_'+data_key][:len(x)]\n",
    "                    plt.plot(x, mean, label=traductor_exp(exp_name), color=color_map[exp_name])\n",
    "                    plt.fill_between(x, mean - ste, mean + ste, color=color_map[exp_name], alpha=0.2)\n",
    "            plt.title(f\"{data_key} - {env} - {type_id}\")\n",
    "            plt.xlabel(\"Steps\")\n",
    "            plt.ylabel(\"Normalized value (%)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            # except Exception as e:\n",
    "            #     print(e)\n",
    "            #     print(f\"Error in {exp_name} - {env} - {type_id} - {data_key}\")\n",
    "            #     continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot specific run \n",
    "algo = 'ngu_ppo'\n",
    "type_id = 'mujoco'\n",
    "env_name = 'Ant-v3'\n",
    "seed = 1\n",
    "keys = [\"specific/episodic_return\"]\n",
    "fig, ax = plt.subplots()\n",
    "for key in keys:\n",
    "    ax.plot(experiments_data[algo][type_id][env_name][seed]['history_metrics']['global_step'], experiments_data[algo][type_id][env_name][seed]['history_metrics'][key], label=f\"{traductor_exp(algo)}_{type_id}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive-exploration-l2RpiOU3-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
