{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Authenticate with W&B\n",
    "wandb.login(timeout=128)\n",
    "\n",
    "# Configure project and other parameters if necessary\n",
    "project_name = \"contrastive_exploration\"\n",
    "entity = \"pletctj6\"\n",
    "\n",
    "# Retrieve the runs from the project\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{entity}/{project_name}\")\n",
    "\n",
    "# Initialize a list to store coverage and shannon entropy data\n",
    "experiments_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: killed\n"
     ]
    }
   ],
   "source": [
    "run_0 = runs[0]\n",
    "# for run in runs:\n",
    "#     if run.state == \"finished\":\n",
    "#         if run_0 is None:\n",
    "#             run_0 = run\n",
    "#             break\n",
    "print('status:', run_0.state)\n",
    "system_metrics = run_0.history(stream='systemMetrics')\n",
    "for k in system_metrics.keys():\n",
    "    if 'system.cpu.' in k and 'cpu_percent' in k:\n",
    "        print(k)\n",
    "    #     # check all columns of panda series\n",
    "    #     print(system_metrics[k].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5499b8763b6248c587d1c82688f521da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing runs:   0%|          | 0/1527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_run(run):\n",
    "    # Vérification de l'état du run\n",
    "    if run.state != \"finished\":\n",
    "        # print(f\"Skipping run {run.name} because it is not finished.\")\n",
    "        return None\n",
    "    # Récupération de la configuration du run\n",
    "    config = run.config\n",
    "    exp_name = config.get('exp_name', 'unknown_exp')\n",
    "    env_name = config.get('env_id', 'unknown_env')\n",
    "    seed = config.get('seed', 'unknown_seed')\n",
    "    system_metrics = run.history(stream='systemMetrics')\n",
    "    cpu_usage = {}\n",
    "    # per cpu usage \n",
    "    for k in system_metrics.keys():\n",
    "        if 'system.cpu.' in k and 'cpu_percent' in k:\n",
    "            cpu_usage[k] = system_metrics[k].sum()\n",
    "\n",
    "    # Retour des données structurées\n",
    "    return {\n",
    "        'exp_name': exp_name,\n",
    "        'env_name': env_name,\n",
    "        'seed': seed,\n",
    "        'data': {\n",
    "            \"cpu_usage\": cpu_usage,\n",
    "            'config': config\n",
    "        }\n",
    "    }\n",
    "\n",
    "experiments_data = {}\n",
    "max_workers = 8\n",
    "# Utilisation de ThreadPoolExecutor pour paralléliser les exécutions de runs\n",
    "# Spécifiez le nombre de threads avec max_workers, par exemple 4 threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = {executor.submit(process_run, run): run for run in runs}\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing runs\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            exp_name = result['exp_name']\n",
    "            env_name = result['env_name']\n",
    "            seed = result['seed']\n",
    "            data = result['data']\n",
    "\n",
    "            if exp_name not in experiments_data:\n",
    "                experiments_data[exp_name] = {}\n",
    "            if env_name not in experiments_data[exp_name]:\n",
    "                experiments_data[exp_name][env_name] = {}\n",
    "            if seed not in experiments_data[exp_name][env_name]:\n",
    "                experiments_data[exp_name][env_name][seed] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check experiments data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['smm_ppo', 'metra_ppo', 'lsd_ppo', 'ngu_ppo', 'icm_ppo', 'diayn_ppo', 'csd_ppo', 'v2_ppo_lipshitz_adaptive_sampling', 'rnd_ppo', 'ppo', 'v2_ppo_kl_adaptive_sampling', 'v1_ppo_lipshitz_adaptive_sampling', 'aux_ppo', 'apt_ppo', 'v1_ppo_kl_adaptive_sampling'])\n"
     ]
    }
   ],
   "source": [
    "print(experiments_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'memory_usage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(obj)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Créer le DataFrame\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiments_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Visualiser l'utilisation des ressources\u001b[39;00m\n\u001b[1;32m     31\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhitegrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 7\u001b[0m, in \u001b[0;36mdict_to_dataframe\u001b[0;34m(experiments_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed, metrics \u001b[38;5;129;01min\u001b[39;00m seeds\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      6\u001b[0m     cpu_usage \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu_usage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m     memory_usage \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmemory_usage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m     global_step \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_step\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_not_empty(cpu_usage) \u001b[38;5;129;01mand\u001b[39;00m is_not_empty(global_step):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'memory_usage'"
     ]
    }
   ],
   "source": [
    "def dict_to_dataframe(experiments_data):\n",
    "    records = []\n",
    "    for exp_name, envs in experiments_data.items():\n",
    "        for env_name, seeds in envs.items():\n",
    "            for seed, metrics in seeds.items():\n",
    "                cpu_usage = metrics['cpu_usage']\n",
    "                memory_usage = metrics['memory_usage']\n",
    "                global_step = metrics['global_step']\n",
    "                if is_not_empty(cpu_usage) and is_not_empty(global_step):\n",
    "                    for cpu, mem, step in zip(cpu_usage, memory_usage, global_step):\n",
    "                        records.append({\n",
    "                            'exp_name': exp_name,\n",
    "                            'env_name': env_name,\n",
    "                            'seed': seed,\n",
    "                            'cpu_usage': cpu,\n",
    "                            'memory_usage': mem,\n",
    "                            'global_step': step\n",
    "                        })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Fonction pour vérifier si une liste ou une série est vide\n",
    "def is_not_empty(obj):\n",
    "    if isinstance(obj, pd.Series):\n",
    "        return not obj.empty\n",
    "    return bool(obj)\n",
    "\n",
    "# Créer le DataFrame\n",
    "df = dict_to_dataframe(experiments_data)\n",
    "\n",
    "# Visualiser l'utilisation des ressources\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.FacetGrid(df, col=\"env_name\", hue=\"exp_name\", sharey=False, height=5, aspect=1.5)\n",
    "g.map(plt.plot, \"global_step\", \"cpu_usage\")\n",
    "g.add_legend()\n",
    "plt.show()\n",
    "\n",
    "g = sns.FacetGrid(df, col=\"env_name\", hue=\"exp_name\", sharey=False, height=5, aspect=1.5)\n",
    "g.map(plt.plot, \"global_step\", \"memory_usage\")\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive-exploration-OeYI_S-i-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
